{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BinaryTwoStageDesigns - Quickstart\n",
    "\n",
    "This is a [jupyter](http://jupyter.org) notebook using the [Julia](https://julialang.org/) kernel [IJulia.jl](https://github.com/JuliaLang/IJulia.jl) demonstrating the use of the julia package [BinaryTwoStageDesigns](https://github.com/imbi-heidelberg/BinaryTwoStageDesigns).\n",
    "\n",
    "To run this notebook, a working installation of the [Gurobi](http://www.gurobi.com/index) solver and the [corresponding Julia interface](https://github.com/JuliaOpt/Gurobi.jl) for [JuMP](https://jump.readthedocs.io/en/latest/) is required. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "using BinaryTwoStageDesigns\n",
    "using Gurobi, DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting\n",
    "\n",
    "Assume that a new anti-cancer agent is to be tested against a historical response rate of $p_0=0.2$ in a phase-II trial and a response rate of $p_1=0.4$ is expected.\n",
    "The maximal tolerable type-I-error rate for testing $\\mathcal{H}_0:p\\leq p_0$ is 5% and a type-II-error rate of 20% is deemed acceptable at $p_1=0.4$.\n",
    "The corresponding single-stage design would require $n=47$ patients in this situation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p0   = 0.2\n",
    "p1   = 0.4\n",
    "tter = 0.2\n",
    "toer = 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adaptive Design\n",
    "\n",
    "Alternatively, a two-stage adaptive design could be used which minimizes the expected sample size under $p_1=0.4$ subject to the same constraints. \n",
    "Additionally, for operational reasons a potential second stage must enroll at least 5 patients. Also, upon rejection of the null hypothesis, at least 25 patients must be enrolled to ensure a sufficiently precise effect estimate for subsequent phase-III planning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample Space\n",
    "\n",
    "First, a sample space object is defined. It simply holds infomarion about the allowable search space for the optimization algorithm. Here, the range of possible stage-one sample sizes is limited to 10 to 20 and the maximal overall sample size to 75. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = SampleSpace(\n",
    "    10:20, # n1 range\n",
    "    75     # nmax\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters\n",
    "\n",
    "Next, the design parameters are also stored in an object. The simplest parameters object corresponds to minimising expected sample size. For a `MESS`-object only $p_0, p_1$, maximal type one and two error rates and the parameter value for which the expected sample size is to be minimized are required besides the sample space object created earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params1 = MESS(\n",
    "    s,                         # sample space\n",
    "    p0, p1;                    # null and planning alternative\n",
    "    alpha = toer, beta = tter, # max. type one and two error rates\n",
    "    pess = p1                  # alternative on which to minimize expected sample size\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization\n",
    "\n",
    "Finally, a solver can be defined and the optimization process is started. Note that both the optimal design as well as all design found while exhaustively exploting the $n_1$-space are returned. The basic technique via integer programming has been desribed in [Kunzmann & Kieser 2016](https://arxiv.org/abs/1605.00249)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MESS"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Gurobi.GurobiSolver(nothing, Any[(:OutputFlag, 0), (:MIPGap, 0.001)])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solver = GurobiSolver(OutputFlag = 0, MIPGap = .001) # no output and max. 0.1% worse than global optimum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "optimizing design for parameters ''\n",
      "considering 11 stage-one sample sizes between 10 and 20 using Gurobi.GurobiSolver as solver\n",
      "\n",
      "    time    n1   % done   sol. time [s]   cum. time [min]       score        best   % diff to best\n",
      "20:00:07    10      9.1              11               0.2   +2.59e+01   +2.59e+01              0.0\n",
      "\n",
      "\n",
      "    time    n1   % done   sol. time [s]   cum. time [min]       score        best   % diff to best\n",
      "20:00:18    11     18.2               9               0.3   +2.53e+01   +2.53e+01              0.0\n",
      "\n",
      "\n",
      "    time    n1   % done   sol. time [s]   cum. time [min]       score        best   % diff to best\n",
      "20:00:27    12     27.3              11               0.5   +2.49e+01   +2.49e+01              0.0\n",
      "\n",
      "\n",
      "    time    n1   % done   sol. time [s]   cum. time [min]       score        best   % diff to best\n",
      "20:00:38    13     36.4              10               0.7   +2.48e+01   +2.48e+01              0.0\n",
      "\n",
      "\n",
      "    time    n1   % done   sol. time [s]   cum. time [min]       score        best   % diff to best\n",
      "20:00:48    14     45.5              13               0.9   +2.47e+01   +2.47e+01              0.0\n",
      "\n",
      "\n",
      "    time    n1   % done   sol. time [s]   cum. time [min]       score        best   % diff to best\n",
      "20:01:01    15     54.5              23               1.3   +2.45e+01   +2.45e+01              0.0\n",
      "\n",
      "\n",
      "    time    n1   % done   sol. time [s]   cum. time [min]       score        best   % diff to best\n",
      "20:01:24    16     63.6              11               1.5   +2.43e+01   +2.43e+01              0.0\n",
      "\n",
      "\n",
      "    time    n1   % done   sol. time [s]   cum. time [min]       score        best   % diff to best\n",
      "20:01:36    17     72.7              19               1.8   +2.47e+01   +2.43e+01              1.5\n",
      "\n",
      "\n",
      "    time    n1   % done   sol. time [s]   cum. time [min]       score        best   % diff to best\n",
      "20:01:55    18     81.8              13               2.0   +2.46e+01   +2.43e+01              0.9\n",
      "\n",
      "\n",
      "    time    n1   % done   sol. time [s]   cum. time [min]       score        best   % diff to best\n",
      "20:02:08    19     90.9              19               2.3   +2.46e+01   +2.43e+01              0.9\n",
      "\n",
      "\n",
      "    time    n1   % done   sol. time [s]   cum. time [min]       score        best   % diff to best\n",
      "20:02:27    20    100.0              15               2.6   +2.47e+01   +2.43e+01              1.6\n",
      "\n",
      "\n",
      "\n",
      "done after 3 minutes.\n",
      "Optimal stage-one sample size is 16 resulting in a minimal score of 2.43e+01\n",
      "\n"
     ]
    }
   ],
   "source": [
    "design1, res1 = optimaldesign(params1, solver, VERBOSE = 1)\n",
    "DataFrame(design1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bayesian approach\n",
    "\n",
    "Alternatively, a Bayesian design criterion can be used where the expected sample size under a prior distribution is minimized subject to a constraint on expected power.\n",
    "To this end, the minimal clinically relevant response rate $p_{MCR}$ must be defined. \n",
    "Here we assume that $p_{MCR}=p_0+0.1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.30000000000000004"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pmcr = p0 + .1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the prior, we simply define a Beta distribution with mass centered slightly below $0.4$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "prior (generic function with 1 method)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RV = Distributions.Beta(5, 8)\n",
    "Distributions.mean(RV)\n",
    "prior(p) = Distributions.pdf(RV, p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, for operational reasons additional constraints on the feasible region, i.e., the sample space are imposed.\n",
    "Often, it will be sensible to require a certain minimal number of subjects for the second stage to outweight the operational burden of an interim analysis (here: 5) and to require a certain minimal number upon rejection of the null hypothesis to ensure a sufficient precision of the response rate estimate when going on to a subsequent phase III trial (here: 25)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s2 = SampleSpace(\n",
    "    10:20,\n",
    "    75,   \n",
    "    n2min = 5, # minmal stage-two sample size\n",
    "    nmincont = 25 # minimal sample size upon rejection of the null\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SampleSpace"
     ]
    }
   ],
   "source": [
    "params2 = MBESS(\n",
    "    s2,                       # sample space\n",
    "    p0, pmcr, prior,          # null, pmcrv, and prior\n",
    "    alpha = toer, beta = tter # max. type one error rate and expected type two error rates\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MBESS"
     ]
    }
   ],
   "source": [
    "# design2, res2 = optimaldesign(params2, solver, VERBOSE = 1)\n",
    "# DataFrame(design2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference\n",
    "\n",
    "After completing the trial with 5/16 responses in stage one and 10/6 in stage two, a point estimate and confidence iterval are required. Point estimates were discussed in [Kunzmann & Kieser 2016](http://onlinelibrary.wiley.com/doi/10.1002/sim.7200/abstract) and different estimators are implemented. Here, we use a compatible minimum expected mean squared error estimator with several favorable properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.43694398967134523"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "est = OCEstimator(design1, solver)\n",
    "estimate(est, 5, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The maximum likelihood estimator (MLE) would have been:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4411764705882353"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(5 + 10) / (samplesize(design1, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Any estimator induces an ordering on the sample space which in turn implies p values. The major advantage of the novel optimal compatible estimators in [Kunzmann & Kieser 2016](http://onlinelibrary.wiley.com/doi/10.1002/sim.7200/abstract) is the fact that their implied p values are *always* compatible with the design's test decision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00750164919381819"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pvalue(est, 5, 10, p0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The very same ordering/p values can then be used to derive a Clopper-Pearson type confidence interval (paper under review):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2-element Array{Float64,1}:\n",
       " 0.271\n",
       " 0.647"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ci = ECPInterval(est, confidence = .9)\n",
    "limits(ci, 5, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.6.0",
   "language": "julia",
   "name": "julia-0.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
